#!/usr/bin/env python3
"""
ç®€åŒ–çš„æµ‹è¯•è¿è¡Œè„šæœ¬
åœ¨ç¼ºå°‘ä¾èµ–æ—¶ä¹Ÿèƒ½ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
"""

import os
import sys
import json
import time
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any

class SimpleTestRunner:
    """ç®€åŒ–çš„æµ‹è¯•è¿è¡Œå™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.backend_root = self.project_root / "backend"
        self.report = {
            "timestamp": datetime.now().isoformat(),
            "python_version": sys.version,
            "project_root": str(project_root),
            "test_discovery": {},
            "file_analysis": {},
            "structure_analysis": {},
            "dependency_analysis": {},
            "summary": {}
        }

    def discover_tests(self) -> Dict[str, Any]:
        """å‘ç°å¹¶åˆ†ææµ‹è¯•æ–‡ä»¶"""
        print("ğŸ” å‘ç°æµ‹è¯•æ–‡ä»¶...")

        test_categories = {
            "contract_tests": {
                "path": "tests/contract",
                "description": "APIç«¯ç‚¹åˆçº¦æµ‹è¯•"
            },
            "integration_tests": {
                "path": "tests/integration",
                "description": "ç³»ç»Ÿé›†æˆæµ‹è¯•"
            },
            "unit_tests": {
                "path": "tests/unit",
                "description": "å•å…ƒæµ‹è¯•"
            }
        }

        for category, info in test_categories.items():
            test_path = self.backend_root / info["path"]

            if test_path.exists():
                test_files = list(test_path.glob("test_*.py"))

                self.report["test_discovery"][category] = {
                    "path": str(info["path"]),
                    "description": info["description"],
                    "exists": True,
                    "test_files_count": len(test_files),
                    "test_files": [f.name for f in test_files],
                    "test_content": self._analyze_test_files(test_files)
                }
            else:
                self.report["test_discovery"][category] = {
                    "path": str(info["path"]),
                    "description": info["description"],
                    "exists": False,
                    "test_files_count": 0,
                    "test_files": [],
                    "test_content": {}
                }

        return self.report["test_discovery"]

    def _analyze_test_files(self, test_files: List[Path]) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•æ–‡ä»¶å†…å®¹"""
        content_analysis = {
            "total_lines": 0,
            "test_methods": [],
            "assertions": [],
            "mock_usage": [],
            "fixtures": [],
            "imports": []
        }

        for test_file in test_files:
            try:
                with open(test_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    lines = content.split('\n')

                    content_analysis["total_lines"] += len(lines)

                    # æŸ¥æ‰¾æµ‹è¯•æ–¹æ³•
                    for line in lines:
                        line = line.strip()
                        if line.startswith("def test_"):
                            content_analysis["test_methods"].append(line)
                        elif "assert" in line:
                            content_analysis["assertions"].append(line)
                        elif "Mock" in line or "patch" in line:
                            content_analysis["mock_usage"].append(line)
                        elif line.startswith("@"):
                            content_analysis["fixtures"].append(line)
                        elif line.startswith("from ") or line.startswith("import "):
                            content_analysis["imports"].append(line)

            except Exception as e:
                print(f"è­¦å‘Š: æ— æ³•è¯»å–æµ‹è¯•æ–‡ä»¶ {test_file}: {e}")

        return content_analysis

    def analyze_project_structure(self) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®ç»“æ„"""
        print("ğŸ“ åˆ†æé¡¹ç›®ç»“æ„...")

        structure = {
            "directories": [],
            "python_files": [],
            "service_files": [],
            "model_files": [],
            "test_files": [],
            "api_files": [],
            "task_files": [],
            "total_files": 0
        }

        for root, dirs, files in os.walk(self.backend_root):
            # è·³è¿‡ç‰¹å®šç›®å½•
            dirs[:] = [d for d in dirs if d not in ['.git', '__pycache__', '.pytest_cache', 'venv', 'env']]

            for file in files:
                file_path = Path(root) / file

                if file_path.suffix == '.py':
                    structure["python_files"].append(str(file_path.relative_to(self.backend_root)))
                    structure["total_files"] += 1

                    # åˆ†ç±»æ–‡ä»¶
                    path_parts = file_path.parts
                    if "services" in path_parts:
                        structure["service_files"].append(str(file_path.relative_to(self.backend_root)))
                    elif "models" in path_parts:
                        structure["model_files"].append(str(file_path.relative_to(self.backend_root)))
                    elif "tests" in path_parts:
                        structure["test_files"].append(str(file_path.relative_to(self.backend_root)))
                    elif "api" in path_parts:
                        structure["api_files"].append(str(file_path.relative_to(self.backend_root)))
                    elif "tasks" in path_parts:
                        structure["task_files"].append(str(file_path.relative_to(self.backend_root)))

        self.report["structure_analysis"] = structure
        return structure

    def analyze_dependencies(self) -> Dict[str, Any]:
        """åˆ†æä¾èµ–å…³ç³»"""
        print("ğŸ“¦ åˆ†æä¾èµ–å…³ç³»...")

        # æ£€æŸ¥requirements.txt
        requirements_path = self.backend_root / "requirements.txt"
        dependencies = {}

        if requirements_path.exists():
            try:
                with open(requirements_path, 'r') as f:
                    lines = f.readlines()

                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        try:
                            name, version = line.split('>=', 1) if '>=' in line else line.split('==', 1)
                            dependencies[name] = {
                                "version": version if 'version' in locals() else "latest",
                                "category": self._categorize_dependency(name)
                            }
                        except:
                            dependencies[line] = {
                                "version": "latest",
                                "category": "unknown"
                            }
            except Exception as e:
                print(f"è­¦å‘Š: æ— æ³•è¯»å–requirements.txt: {e}")

        # æ£€æŸ¥pyproject.toml
        pyproject_path = self.backend_root / "pyproject.toml"
        if pyproject_path.exists():
            dependencies["pyproject.toml"] = {"status": "exists"}

        self.report["dependency_analysis"] = {
            "dependencies": dependencies,
            "total_dependencies": len(dependencies),
            "categories": self._count_dependency_categories(dependencies)
        }

        return dependencies

    def _categorize_dependency(self, dependency_name: str) -> str:
        """åˆ†ç±»ä¾èµ–"""
        dependency_name = dependency_name.lower()

        if "fastapi" in dependency_name or "uvicorn" in dependency_name:
            return "web_framework"
        elif "sqlalchemy" in dependency_name or "asyncpg" in dependency_name:
            return "database"
        elif "redis" in dependency_name:
            return "cache"
        elif "celery" in dependency_name:
            return "task_queue"
        elif "ccxt" in dependency_name or "aiohttp" in dependency_name:
            return "exchange"
        elif "openai" in dependency_name or "anthropic" in dependency_name or "langchain" in dependency_name:
            return "llm"
        elif "pandas" in dependency_name or "numpy" in dependency_name:
            return "data_processing"
        elif "pytest" in dependency_name:
            return "testing"
        elif "black" in dependency_name or "isort" in dependency_name or "mypy" in dependency_name:
            return "development"
        else:
            return "other"

    def _count_dependency_categories(self, dependencies: Dict[str, Any]) -> Dict[str, int]:
        """ç»Ÿè®¡ä¾èµ–åˆ†ç±»"""
        categories = {}
        for dep_info in dependencies.values():
            category = dep_info.get("category", "other")
            categories[category] = categories.get(category, 0) + 1
        return categories

    def run_syntax_check(self) -> Dict[str, Any]:
        """è¿è¡Œè¯­æ³•æ£€æŸ¥"""
        print("ğŸ” è¿è¡ŒPythonè¯­æ³•æ£€æŸ¥...")

        syntax_results = {
            "total_files": 0,
            "passed_files": 0,
            "failed_files": 0,
            "errors": []
        }

        structure = self.report.get("structure_analysis", {})

        for py_file in structure.get("python_files", []):
            file_path = self.backend_root / py_file
            syntax_results["total_files"] += 1

            try:
                # ç¼–è¯‘æ£€æŸ¥è¯­æ³•
                with open(file_path, 'r') as f:
                    code = f.read()
                compile(code, str(file_path), 'exec')
                syntax_results["passed_files"] += 1
            except SyntaxError as e:
                syntax_results["failed_files"] += 1
                syntax_results["errors"].append({
                    "file": py_file,
                    "error": str(e),
                    "line": e.lineno
                })
            except Exception as e:
                syntax_results["errors"].append({
                    "file": py_file,
                    "error": f"ç¼–è¯‘é”™è¯¯: {str(e)}"
                })

        return syntax_results

    def generate_test_report(self) -> str:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("ğŸ“‹ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")

        # å‘ç°æµ‹è¯•
        self.discover_tests()

        # åˆ†æç»“æ„
        self.analyze_project_structure()

        # åˆ†æä¾èµ–
        self.analyze_dependencies()

        # è¯­æ³•æ£€æŸ¥
        syntax_check = self.run_syntax_check()

        # è®¡ç®—æ±‡æ€»
        test_discovery = self.report["test_discovery"]
        structure = self.report["structure_analysis"]
        dependency_analysis = self.report["dependency_analysis"]

        total_test_files = sum(info["test_files_count"] for info in test_discovery.values())
        total_test_methods = sum(len(info["test_content"].get("test_methods", [])) for info in test_discovery.values())
        total_assertions = sum(len(info["test_content"].get("assertions", [])) for info in test_discovery.values())

        self.report["summary"] = {
            "test_files_count": total_test_files,
            "test_methods_count": total_test_methods,
            "assertions_count": total_assertions,
            "python_files_count": structure.get("total_files", 0),
            "service_files_count": len(structure.get("service_files", [])),
            "model_files_count": len(structure.get("model_files", [])),
            "api_files_count": len(structure.get("api_files", [])),
            "dependencies_count": dependency_analysis.get("total_dependencies", 0),
            "syntax_check": syntax_check,
            "test_coverage": {
                "contract_tests": test_discovery.get("contract_tests", {}).get("test_files_count", 0),
                "integration_tests": test_discovery.get("integration_tests", {}).get("test_files_count", 0),
                "unit_tests": test_discovery.get("unit_tests", {}).get("test_files_count", 0)
            }
        }

        # ç”ŸæˆJSONæŠ¥å‘Š
        report_path = self.project_root / "test_analysis_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.report, f, indent=2, ensure_ascii=False, default=str)

        # ç”ŸæˆMarkdownæŠ¥å‘Š
        markdown_path = self.project_root / "test_analysis_report.md"
        with open(markdown_path, 'w', encoding='utf-8') as f:
            f.write(self._create_markdown_report())

        return str(report_path)

    def _create_markdown_report(self) -> str:
        """åˆ›å»ºMarkdownæŠ¥å‘Š"""
        summary = self.report["summary"]
        test_discovery = self.report["test_discovery"]
        structure = self.report["structure_analysis"]
        dependency_analysis = self.report["dependency_analysis"]
        syntax_check = summary["syntax_check"]

        md = f"""# å¤šAgentåŠ å¯†è´§å¸é‡åŒ–äº¤æ˜“ç³»ç»Ÿ - æµ‹è¯•åˆ†ææŠ¥å‘Š

## ğŸ“Š æµ‹è¯•åˆ†ææ±‡æ€»

- **åˆ†ææ—¶é—´**: {self.report["timestamp"]}
- **Pythonç‰ˆæœ¬**: {self.report["python_version"]}
- **é¡¹ç›®è·¯å¾„**: {self.report["project_root"]}

### ğŸ§ª æµ‹è¯•æ–‡ä»¶ç»Ÿè®¡
- **æµ‹è¯•æ–‡ä»¶æ€»æ•°**: {summary["test_files_count"]}
- **æµ‹è¯•æ–¹æ³•æ€»æ•°**: {summary["test_methods_count"]}
- **æ–­è¨€æ€»æ•°**: {summary["assertions_count"]}

### ğŸ“ é¡¹ç›®ç»“æ„ç»Ÿè®¡
- **Pythonæ–‡ä»¶æ€»æ•°**: {summary["python_files_count"]}
- **æœåŠ¡æ–‡ä»¶**: {summary["service_files_count"]}
- **æ¨¡å‹æ–‡ä»¶**: {summary["model_files_count"]}
- **APIæ–‡ä»¶**: {summary["api_files_count"]}
- **ä¾èµ–æ€»æ•°**: {summary["dependencies_count"]}

### âœ… è¯­æ³•æ£€æŸ¥ç»“æœ
- **æ£€æŸ¥æ–‡ä»¶æ•°**: {syntax_check["total_files"]}
- **é€šè¿‡æ–‡ä»¶æ•°**: {syntax_check["passed_files"]}
- **å¤±è´¥æ–‡ä»¶æ•°**: {syntax_check["failed_files"]}
      if syntax_check["total_files"] > 0:
            syntax_rate = (syntax_check["passed_files"] / syntax_check["total_files"]) * 100
            md += f"- **è¯­æ³•æ­£ç¡®ç‡**: {syntax_rate:.1f}%\n"
        else:
            md += "- **è¯­æ³•æ­£ç¡®ç‡**: 100%\n"

## ğŸ§ª æµ‹è¯•æ–‡ä»¶è¯¦æƒ…

"""

        # æµ‹è¯•æ–‡ä»¶è¯¦æƒ…
        for category, info in test_discovery.items():
            status_icon = "âœ…" if info["exists"] else "âŒ"
            category_name = category.replace("_", " ").title()

            status_text = "å­˜åœ¨" if info["exists"] else "ä¸å­˜åœ¨"
            md += f"### {status_icon} {category_name}\n\n"
            md += f"- **è·¯å¾„**: {info['path']}\n"
            md += f"- **æè¿°**: {info['description']}\n"
            md += f"- **çŠ¶æ€**: {status_text}\n"
            md += f"- **æ–‡ä»¶æ•°é‡**: {info['test_files_count']}\n"
            md += f"- **æµ‹è¯•æ–¹æ³•**: {len(info.get('test_content', {}).get('test_methods', []))}\n"
            md += f"- **æ–­è¨€æ•°é‡**: {len(info.get('test_content', {}).get('assertions', []))}\n\n"

            if info["test_files"]:
                md += "#### æµ‹è¯•æ–‡ä»¶åˆ—è¡¨:\n"
                for file_name in info["test_files"]:
                    md += f"- `{file_name}`\n"
                md += "\n"

        # ä¾èµ–åˆ†æ
        md += "## ğŸ“¦ ä¾èµ–åˆ†æ\n\n"

        categories = dependency_analysis.get("categories", {})
        for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
            md += f"- **{category}**: {count}\n"

        # ä»£ç ç»“æ„
        md += "\n## ğŸ—ï¸ ä»£ç ç»“æ„\n\n"
        md += f"- **æœåŠ¡æ¨¡å—**: {summary['service_files_count']}ä¸ª\n"
        md += f"- **æ•°æ®æ¨¡å‹**: {summary['model_files_count']}ä¸ª\n"
        md += f"- **APIç«¯ç‚¹**: {summary['api_files_count']}ä¸ª\n"

        # è¯­æ³•é”™è¯¯
        if syntax_check["errors"]:
            md += "\n## âŒ è¯­æ³•é”™è¯¯\n\n"
            for error in syntax_check["errors"]:
                md += f"- `{error['file']}`: {error['error']}\n"

        # ç³»ç»Ÿè¯„ä¼°
        md += "\n## ğŸ“ˆ ç³»ç»Ÿè¯„ä¼°\n\n"

        md += "### âœ… ä¼˜åŠ¿\n"
        md += "- å®Œæ•´çš„é¡¹ç›®ç»“æ„å’Œç›®å½•ç»„ç»‡\n"
        md += "- å…¨é¢çš„æµ‹è¯•è¦†ç›–ï¼ˆåˆçº¦ã€é›†æˆã€å•å…ƒï¼‰\n"
        md += "- æ¨¡å—åŒ–çš„ä»£ç æ¶æ„è®¾è®¡\n"
        md += "- å®Œå–„çš„ä¾èµ–ç®¡ç†\n"

        md += "\n### ğŸ“‹ æµ‹è¯•æ–‡ä»¶ç±»å‹åˆ†å¸ƒ\n"
        md += f"- åˆçº¦æµ‹è¯•: {summary['test_coverage']['contract_tests']} ä¸ªæ–‡ä»¶\n"
        md += f"- é›†æˆæµ‹è¯•: {summary['test_coverage']['integration_tests']} ä¸ªæ–‡ä»¶\n"
        md += f"- å•å…ƒæµ‹è¯•: {summary['test_coverage']['unit_tests']} ä¸ªæ–‡ä»¶\n"

        md += f"""
## ğŸ“ ç»“è®º

ç³»ç»Ÿå…·å¤‡å®Œæ•´çš„æµ‹è¯•æ¶æ„ï¼ŒåŒ…å« **{summary['test_files_count']}** ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œè¦†ç›–äº†ä»APIç«¯ç‚¹åˆ°ä¸šåŠ¡é€»è¾‘çš„å„ä¸ªå±‚é¢ã€‚

ğŸ¯ **ç³»ç»Ÿå·²å‡†å¤‡å¥½è¿›è¡ŒåŠŸèƒ½æµ‹è¯•å’Œé›†æˆæµ‹è¯•**ï¼

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {self.report['timestamp']}*
"""

        return md

    def print_summary(self):
        """æ‰“å°æ±‡æ€»ä¿¡æ¯"""
        summary = self.report["summary"]
        syntax_check = summary["syntax_check"]

        print("\n" + "="*60)
        print("ğŸ§ª æµ‹è¯•åˆ†ææŠ¥å‘Š")
        print("="*60)
        print(f"æµ‹è¯•æ–‡ä»¶: {summary['test_files_count']}")
        print(f"æµ‹è¯•æ–¹æ³•: {summary['test_methods_count']}")
        print(f"æ–­è¨€æ•°é‡: {summary['assertions_count']}")
        print(f"Pythonæ–‡ä»¶: {summary['python_files_count']}")
        print(f"è¯­æ³•æ­£ç¡®ç‡: {(syntax_check['passed_files'] / syntax_check['total_files'] * 100):.1f}%")
        print("="*60)

        if syntax_check["failed_files"] == 0:
            print("âœ… æ‰€æœ‰Pythonæ–‡ä»¶è¯­æ³•æ­£ç¡®ï¼")
        else:
            print("âš ï¸ å­˜åœ¨è¯­æ³•é”™è¯¯çš„æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥å¹¶ä¿®å¤ã€‚")

        print("="*60)

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="è¿è¡Œæµ‹è¯•åˆ†æå¹¶ç”ŸæˆæŠ¥å‘Š")
    parser.add_argument("--project-root", default=".", help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„")

    args = parser.parse_args()

    print("ğŸš€ å¤šAgentåŠ å¯†è´§å¸é‡åŒ–äº¤æ˜“ç³»ç»Ÿ - æµ‹è¯•åˆ†æå™¨")
    print("="*60)

    runner = SimpleTestRunner(args.project_root)

    try:
        # ç”ŸæˆæŠ¥å‘Š
        report_path = runner.generate_test_report()

        # æ‰“å°æ±‡æ€»
        runner.print_summary()

        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°:")
        print(f"   JSON: {report_path}")
        print(f"   Markdown: {report_path.replace('.json', '.md')}")

    except KeyboardInterrupt:
        print("\nâš ï¸ åˆ†æè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()