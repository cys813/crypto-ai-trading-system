#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆæ€§èƒ½åˆ†æè„šæœ¬
ä¸“é—¨é’ˆå¯¹å¤šAgentåŠ å¯†è´§å¸é‡åŒ–äº¤æ˜“ç³»ç»Ÿ
"""

import os
import json
from datetime import datetime
from pathlib import Path

class SimplePerformanceAnalyzer:
    """ç®€åŒ–æ€§èƒ½åˆ†æå™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.backend_root = self.project_root / "backend"
        self.report = {
            "timestamp": datetime.now().isoformat(),
            "project_root": str(project_root),
            "analysis": {},
            "recommendations": [],
            "performance_score": {}
        }

    def analyze_system(self):
        """åˆ†æç³»ç»Ÿæ€§èƒ½"""
        print("ğŸ“Š åˆ†æç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡...")

        # ä»£ç åˆ†æ
        self.analyze_code_structure()

        # ä¾èµ–åˆ†æ
        self.analyze_dependencies()

        # æ¶æ„åˆ†æ
        self.analyze_architecture()

        # ç”Ÿæˆå»ºè®®
        self.generate_recommendations()

        # è®¡ç®—è¯„åˆ†
        self.calculate_score()

        return self.report

    def analyze_code_structure(self):
        """åˆ†æä»£ç ç»“æ„"""
        print("ğŸ—ï¸ åˆ†æä»£ç ç»“æ„...")

        code_stats = {
            "total_files": 0,
            "total_lines": 0,
            "large_files": [],
            "module_distribution": {},
            "test_coverage": {
                "test_files": 0,
                "test_lines": 0
            }
        }

        try:
            python_files = list(self.backend_root.rglob("*.py"))
            code_stats["total_files"] = len(python_files)

            file_sizes = []
            for py_file in python_files:
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        lines = len(f.readlines())
                        code_stats["total_lines"] += lines
                        file_sizes.append((str(py_file.relative_to(self.backend_root)), lines))

                        # ç»Ÿè®¡æ¨¡å—åˆ†å¸ƒ
                        path_parts = py_file.parts
                        if len(path_parts) > 2:
                            module = path_parts[-2]
                            if module not in code_stats["module_distribution"]:
                                code_stats["module_distribution"][module] = {"files": 0, "lines": 0}
                            code_stats["module_distribution"][module]["files"] += 1
                            code_stats["module_distribution"][module]["lines"] += lines

                        # ç»Ÿè®¡æµ‹è¯•æ–‡ä»¶
                        if "test" in str(py_file).lower():
                            code_stats["test_coverage"]["test_files"] += 1
                            code_stats["test_coverage"]["test_lines"] += lines

                except:
                    continue

            # æ‰¾å‡ºæœ€å¤§çš„æ–‡ä»¶
            file_sizes.sort(key=lambda x: x[1], reverse=True)
            code_stats["largest_files"] = file_sizes[:10]

        except Exception as e:
            print(f"ä»£ç ç»“æ„åˆ†æå¤±è´¥: {e}")

        self.report["analysis"]["code_structure"] = code_stats

    def analyze_dependencies(self):
        """åˆ†æä¾èµ–å…³ç³»"""
        print("ğŸ“¦ åˆ†æä¾èµ–å…³ç³»...")

        dep_stats = {
            "external_deps": 0,
            "internal_deps": 0,
            "heavy_libs": [],
            "categories": {}
        }

        try:
            # åˆ†ærequirements.txt
            req_path = self.backend_root / "requirements.txt"
            if req_path.exists():
                with open(req_path, 'r') as f:
                    lines = f.readlines()

                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        dep_stats["external_deps"] += 1

                        # åˆ†ç±»ä¾èµ–
                        lib_name = line.split('=')[0].split('[')[0].lower()
                        category = self._categorize_dependency(lib_name)
                        if category not in dep_stats["categories"]:
                            dep_stats["categories"][category] = 0
                        dep_stats["categories"][category] += 1

                        # è¯†åˆ«é‡å‹åº“
                        if lib_name in ['pandas', 'numpy', 'tensorflow', 'torch', 'scikit-learn']:
                            dep_stats["heavy_libs"].append(line)

            # ç»Ÿè®¡å†…éƒ¨ä¾èµ–
            python_files = list(self.backend_root.rglob("*.py"))
            for py_file in python_files[:30]:  # é‡‡æ ·åˆ†æ
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        # ç»Ÿè®¡å†…éƒ¨å¯¼å…¥
                        if 'from ..' in content or 'from .' in content:
                            dep_stats["internal_deps"] += content.count('from ..') + content.count('from .')
                except:
                    continue

        except Exception as e:
            print(f"ä¾èµ–åˆ†æå¤±è´¥: {e}")

        self.report["analysis"]["dependencies"] = dep_stats

    def analyze_architecture(self):
        """åˆ†ææ¶æ„"""
        print("ğŸ›ï¸ åˆ†æç³»ç»Ÿæ¶æ„...")

        arch_stats = {
            "layers": {
                "api": {"files": 0, "lines": 0},
                "services": {"files": 0, "lines": 0},
                "models": {"files": 0, "lines": 0},
                "core": {"files": 0, "lines": 0},
                "tasks": {"files": 0, "lines": 0}
            },
            "async_functions": 0,
            "database_models": 0,
            "api_endpoints": 0,
            "background_tasks": 0
        }

        try:
            python_files = list(self.backend_root.rglob("*.py"))

            for py_file in python_files:
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        lines = len(content.split('\n'))

                        # åˆ†ç±»åˆ°ä¸åŒå±‚æ¬¡
                        path_parts = py_file.parts
                        if "api" in path_parts:
                            arch_stats["layers"]["api"]["files"] += 1
                            arch_stats["layers"]["api"]["lines"] += lines
                            arch_stats["api_endpoints"] += content.count('@router.') + content.count('@app.')
                        elif "services" in path_parts:
                            arch_stats["layers"]["services"]["files"] += 1
                            arch_stats["layers"]["services"]["lines"] += lines
                            arch_stats["async_functions"] += content.count('async def')
                        elif "models" in path_parts:
                            arch_stats["layers"]["models"]["files"] += 1
                            arch_stats["layers"]["models"]["lines"] += lines
                            if 'class ' in content and ('Base' in content or 'Model' in content):
                                arch_stats["database_models"] += 1
                        elif "core" in path_parts:
                            arch_stats["layers"]["core"]["files"] += 1
                            arch_stats["layers"]["core"]["lines"] += lines
                        elif "tasks" in path_parts:
                            arch_stats["layers"]["tasks"]["files"] += 1
                            arch_stats["layers"]["tasks"]["lines"] += lines
                            arch_stats["background_tasks"] += content.count('@task') + content.count('@celery')

                except:
                    continue

        except Exception as e:
            print(f"æ¶æ„åˆ†æå¤±è´¥: {e}")

        self.report["analysis"]["architecture"] = arch_stats

    def generate_recommendations(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        print("ğŸ’¡ ç”Ÿæˆä¼˜åŒ–å»ºè®®...")

        recommendations = []

        # åŸºäºä»£ç ç»“æ„çš„å»ºè®®
        code_stats = self.report["analysis"].get("code_structure", {})
        total_lines = code_stats.get("total_lines", 0)
        large_files = code_stats.get("largest_files", [])

        if total_lines > 25000:
            recommendations.append({
                "category": "ä»£ç è§„æ¨¡",
                "priority": "ä¸­",
                "issue": f"ä»£ç åº“è§„æ¨¡è¾ƒå¤§ ({total_lines} è¡Œ)",
                "suggestion": "è€ƒè™‘æ¨¡å—åŒ–æ‹†åˆ†ï¼Œå°†ç›¸å…³åŠŸèƒ½ç»„ç»‡åˆ°ç‹¬ç«‹å­æ¨¡å—",
                "impact": "æé«˜å¯ç»´æŠ¤æ€§å’Œå›¢é˜Ÿåä½œæ•ˆç‡"
            })

        if large_files and large_files[0][1] > 800:
            recommendations.append({
                "category": "æ–‡ä»¶å¤§å°",
                "priority": "é«˜",
                "issue": f"å­˜åœ¨è¶…å¤§æ–‡ä»¶: {large_files[0][1]} è¡Œ",
                "suggestion": "å°†å¤§æ–‡ä»¶æŒ‰åŠŸèƒ½æ‹†åˆ†ä¸ºå¤šä¸ªå°æ–‡ä»¶",
                "impact": "æé«˜ä»£ç å¯è¯»æ€§å’Œç»´æŠ¤æ€§"
            })

        # åŸºäºæ¶æ„çš„å»ºè®®
        arch_stats = self.report["analysis"].get("architecture", {})
        async_funcs = arch_stats.get("async_functions", 0)
        api_endpoints = arch_stats.get("api_endpoints", 0)

        if async_funcs < api_endpoints * 0.5:
            recommendations.append({
                "category": "å¼‚æ­¥ç¼–ç¨‹",
                "priority": "é«˜",
                "issue": "APIç«¯ç‚¹å¼‚æ­¥åŒ–ç¨‹åº¦ä¸è¶³",
                "suggestion": "åœ¨APIå±‚ä½¿ç”¨async/awaitæé«˜å¹¶å‘æ€§èƒ½",
                "impact": "æ˜¾è‘—æå‡ç³»ç»Ÿååé‡å’Œå“åº”é€Ÿåº¦"
            })

        # åŸºäºä¾èµ–çš„å»ºè®®
        dep_stats = self.report["analysis"].get("dependencies", {})
        heavy_libs = dep_stats.get("heavy_libs", [])

        if heavy_libs:
            recommendations.append({
                "category": "ä¾èµ–ä¼˜åŒ–",
                "priority": "ä½",
                "issue": f"å­˜åœ¨é‡å‹ä¾èµ–åº“: {len(heavy_libs)} ä¸ª",
                "suggestion": "è¯„ä¼°æ˜¯å¦å¯ä½¿ç”¨è½»é‡çº§æ›¿ä»£æˆ–æŒ‰éœ€åŠ è½½",
                "impact": "å‡å°‘å†…å­˜å ç”¨å’Œå¯åŠ¨æ—¶é—´"
            })

        # é€šç”¨ä¼˜åŒ–å»ºè®®
        recommendations.extend([
            {
                "category": "æ€§èƒ½ç›‘æ§",
                "priority": "é«˜",
                "issue": "ç¼ºå°‘æ€§èƒ½ç›‘æ§æœºåˆ¶",
                "suggestion": "é›†æˆAPMå·¥å…·ç›‘æ§å…³é”®æ€§èƒ½æŒ‡æ ‡",
                "impact": "åŠæ—¶å‘ç°æ€§èƒ½ç“¶é¢ˆå’Œä¼˜åŒ–æœºä¼š"
            },
            {
                "category": "ç¼“å­˜ç­–ç•¥",
                "priority": "é«˜",
                "issue": "ç¼ºå°‘ç¼“å­˜å±‚è®¾è®¡",
                "suggestion": "å®ç°Redisç¼“å­˜å‡å°‘æ•°æ®åº“æŸ¥è¯¢",
                "impact": "å¤§å¹…æå‡æŸ¥è¯¢æ€§èƒ½"
            },
            {
                "category": "æ•°æ®åº“ä¼˜åŒ–",
                "priority": "ä¸­",
                "issue": "éœ€è¦æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–",
                "suggestion": "æ·»åŠ é€‚å½“ç´¢å¼•å’ŒæŸ¥è¯¢ä¼˜åŒ–",
                "impact": "æå‡æ•°æ®åº“æ“ä½œæ€§èƒ½"
            }
        ])

        self.report["recommendations"] = recommendations

    def calculate_score(self):
        """è®¡ç®—æ€§èƒ½è¯„åˆ†"""
        print("ğŸ“ˆ è®¡ç®—æ€§èƒ½è¯„åˆ†...")

        scores = {
            "code_quality": 85,  # é»˜è®¤åŸºç¡€åˆ†
            "architecture": 80,
            "performance": 75
        }

        # æ ¹æ®åˆ†æç»“æœè°ƒæ•´åˆ†æ•°
        code_stats = self.report["analysis"].get("code_structure", {})
        total_lines = code_stats.get("total_lines", 0)
        large_files = code_stats.get("largest_files", [])

        if total_lines > 30000:
            scores["code_quality"] -= 10
        if large_files and large_files[0][1] > 1000:
            scores["code_quality"] -= 15

        arch_stats = self.report["analysis"].get("architecture", {})
        async_ratio = arch_stats.get("async_functions", 0) / max(arch_stats.get("api_endpoints", 1), 1)
        if async_ratio < 0.5:
            scores["performance"] -= 15

        # é€šç”¨åŠ åˆ†é¡¹
        test_files = code_stats.get("test_coverage", {}).get("test_files", 0)
        if test_files > 10:
            scores["code_quality"] += 5

        # è®¡ç®—æ€»åˆ†
        total_score = (scores["code_quality"] + scores["architecture"] + scores["performance"]) / 3

        self.report["performance_score"] = {
            "total_score": round(total_score, 1),
            "grade": self._get_grade(total_score),
            "individual_scores": scores
        }

    def _categorize_dependency(self, lib_name: str) -> str:
        """åˆ†ç±»ä¾èµ–"""
        if any(word in lib_name for word in ['fastapi', 'uvicorn', 'starlette']):
            return "web_framework"
        elif any(word in lib_name for word in ['sqlalchemy', 'asyncpg', 'psycopg']):
            return "database"
        elif any(word in lib_name for word in ['redis', 'aioredis']):
            return "cache"
        elif any(word in lib_name for word in ['celery', 'flower']):
            return "task_queue"
        elif any(word in lib_name for word in ['pandas', 'numpy', 'scipy']):
            return "data_processing"
        elif any(word in lib_name for word in ['openai', 'anthropic', 'langchain']):
            return "ai_llm"
        elif any(word in lib_name for word in ['pytest', 'pytest-asyncio']):
            return "testing"
        else:
            return "other"

    def _get_grade(self, score: float) -> str:
        """è·å–ç­‰çº§"""
        if score >= 90:
            return "A+ (ä¼˜ç§€)"
        elif score >= 80:
            return "A (è‰¯å¥½)"
        elif score >= 70:
            return "B (ä¸€èˆ¬)"
        elif score >= 60:
            return "C (éœ€è¦æ”¹è¿›)"
        else:
            return "D (æ€¥éœ€ä¼˜åŒ–)"

    def generate_report(self):
        """ç”ŸæˆæŠ¥å‘Š"""
        print("ğŸ“ ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š...")

        # ç”ŸæˆJSONæŠ¥å‘Š
        json_path = self.project_root / "simple_performance_report.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self.report, f, indent=2, ensure_ascii=False)

        # ç”ŸæˆMarkdownæŠ¥å‘Š
        md_path = self.project_root / "simple_performance_report.md"
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(self._create_markdown_report())

        return str(json_path)

    def _create_markdown_report(self) -> str:
        """åˆ›å»ºMarkdownæŠ¥å‘Š"""
        report = self.report
        score = report.get("performance_score", {})

        md = f"""# å¤šAgentåŠ å¯†è´§å¸é‡åŒ–äº¤æ˜“ç³»ç»Ÿ - æ€§èƒ½åˆ†ææŠ¥å‘Š

## ğŸ“Š åˆ†ææ¦‚è§ˆ

**åˆ†ææ—¶é—´**: {report["timestamp"]}
**é¡¹ç›®è·¯å¾„**: {report["project_root"]}

### ğŸ¯ æ€§èƒ½è¯„åˆ†
**æ€»åˆ†**: {score.get("total_score", "N/A")}/100 ({score.get("grade", "N/A")})

| ç»´åº¦ | å¾—åˆ† | è¯„ä»· |
|------|------|------|
| ä»£ç è´¨é‡ | {score.get("individual_scores", {}).get("code_quality", "N/A")} | ä»£ç ç»“æ„å’Œå¯ç»´æŠ¤æ€§ |
| æ¶æ„è®¾è®¡ | {score.get("individual_scores", {}).get("architecture", "N/A")} | ç³»ç»Ÿæ¶æ„åˆç†æ€§ |
| æ€§èƒ½è®¾è®¡ | {score.get("individual_scores", {}).get("performance", "N/A")} | æ€§èƒ½ä¼˜åŒ–ç¨‹åº¦ |

---

## ğŸ“Š ä»£ç ç»“æ„åˆ†æ

### ğŸ—ï¸ é¡¹ç›®è§„æ¨¡
- **æ€»æ–‡ä»¶æ•°**: {report["analysis"].get("code_structure", {}).get("total_files", "N/A")}
- **æ€»ä»£ç è¡Œæ•°**: {report["analysis"].get("code_structure", {}).get("total_lines", "N/A")}

### ğŸ“‹ æ¨¡å—åˆ†å¸ƒ
"""

        modules = report["analysis"].get("code_structure", {}).get("module_distribution", {})
        for module, stats in sorted(modules.items(), key=lambda x: x[1]["lines"], reverse=True)[:10]:
            md += f"- **{module}**: {stats.get('files', 0)} æ–‡ä»¶, {stats.get('lines', 0)} è¡Œ\n"

        md += f"""
### ğŸ“ æœ€å¤§æ–‡ä»¶ (Top 10)
"""

        large_files = report["analysis"].get("code_structure", {}).get("largest_files", [])
        for i, (file_path, lines) in enumerate(large_files[:10], 1):
            md += f"{i}. `{file_path}` - {lines:,} è¡Œ\n"

        md += f"""
### ğŸ§ª æµ‹è¯•è¦†ç›–
- **æµ‹è¯•æ–‡ä»¶**: {report["analysis"].get("code_structure", {}).get("test_coverage", {}).get("test_files", "N/A")}
- **æµ‹è¯•ä»£ç è¡Œæ•°**: {report["analysis"].get("code_structure", {}).get("test_coverage", {}).get("test_lines", "N/A")}

---

## ğŸ“¦ ä¾èµ–åˆ†æ

### ğŸ“Š ä¾èµ–ç»Ÿè®¡
- **å¤–éƒ¨ä¾èµ–**: {report["analysis"].get("dependencies", {}).get("external_deps", "N/A")}
- **å†…éƒ¨ä¾èµ–**: {report["analysis"].get("dependencies", {}).get("internal_deps", "N/A")}

### ğŸ“‹ ä¾èµ–åˆ†ç±»
"""

        categories = report["analysis"].get("dependencies", {}).get("categories", {})
        for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
            md += f"- **{category}**: {count} ä¸ª\n"

        md += f"""
### âš ï¸ é‡å‹ä¾èµ–
"""

        heavy_libs = report["analysis"].get("dependencies", {}).get("heavy_libs", [])
        for lib in heavy_libs:
            md += f"- `{lib}`\n"

        md += f"""

---

## ğŸ›ï¸ æ¶æ„åˆ†æ

### ğŸ“Š åˆ†å±‚ç»Ÿè®¡
| å±‚æ¬¡ | æ–‡ä»¶æ•° | ä»£ç è¡Œæ•° |
|------|--------|----------|
| APIå±‚ | {report["analysis"].get("architecture", {}).get("layers", {}).get("api", {}).get("files", "N/A")} | {report["analysis"].get("architecture", {}).get("layers", {}).get("api", {}).get("lines", "N/A"):,} |
| æœåŠ¡å±‚ | {report["analysis"].get("architecture", {}).get("layers", {}).get("services", {}).get("files", "N/A")} | {report["analysis"].get("architecture", {}).get("layers", {}).get("services", {}).get("lines", "N/A"):,} |
| æ¨¡å‹å±‚ | {report["analysis"].get("architecture", {}).get("layers", {}).get("models", {}).get("files", "N/A")} | {report["analysis"].get("architecture", {}).get("layers", {}).get("models", {}).get("lines", "N/A"):,} |
| æ ¸å¿ƒå±‚ | {report["analysis"].get("architecture", {}).get("layers", {}).get("core", {}).get("files", "N/A")} | {report["analysis"].get("architecture", {}).get("layers", {}).get("core", {}).get("lines", "N/A"):,} |
| ä»»åŠ¡å±‚ | {report["analysis"].get("architecture", {}).get("layers", {}).get("tasks", {}).get("files", "N/A")} | {report["analysis"].get("architecture", {}).get("layers", {}).get("tasks", {}).get("lines", "N/A"):,} |

### ğŸ“ˆ æ¶æ„ç‰¹æ€§
- **å¼‚æ­¥å‡½æ•°**: {report["analysis"].get("architecture", {}).get("async_functions", "N/A")} ä¸ª
- **APIç«¯ç‚¹**: {report["analysis"].get("architecture", {}).get("api_endpoints", "N/A")} ä¸ª
- **æ•°æ®æ¨¡å‹**: {report["analysis"].get("architecture", {}).get("database_models", "N/A")} ä¸ª
- **åå°ä»»åŠ¡**: {report["analysis"].get("architecture", {}).get("background_tasks", "N/A")} ä¸ª

---

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### ğŸ¯ é«˜ä¼˜å…ˆçº§ä¼˜åŒ–
"""

        recommendations = report.get("recommendations", [])
        high_priority = [r for r in recommendations if r.get("priority") == "é«˜"]
        for rec in high_priority:
            md += f"""
#### {rec.get("category", "æœªçŸ¥")}
- **é—®é¢˜**: {rec.get("issue", "æ— ")}
- **å»ºè®®**: {rec.get("suggestion", "æ— ")}
- **é¢„æœŸå½±å“**: {rec.get("impact", "æ— ")}
"""

        md += """
### ğŸ“‹ ä¸­ä¼˜å…ˆçº§ä¼˜åŒ–
"""

        medium_priority = [r for r in recommendations if r.get("priority") == "ä¸­"]
        for rec in medium_priority:
            md += f"""
#### {rec.get("category", "æœªçŸ¥")}
- **é—®é¢˜**: {rec.get("issue", "æ— ")}
- **å»ºè®®**: {rec.get("suggestion", "æ— ")}
- **é¢„æœŸå½±å“**: {rec.get("impact", "æ— ")}
"""

        md += """
### ğŸ“ ä½ä¼˜å…ˆçº§ä¼˜åŒ–
"""

        low_priority = [r for r in recommendations if r.get("priority") == "ä½"]
        for rec in low_priority:
            md += f"""
#### {rec.get("category", "æœªçŸ¥")}
- **é—®é¢˜**: {rec.get("issue", "æ— ")}
- **å»ºè®®**: {rec.get("suggestion", "æ— ")}
- **é¢„æœŸå½±å“**: {rec.get("impact", "æ— ")}
"""

        md += f"""

---

## ğŸ“ˆ æ€»ç»“ä¸è¯„ä¼°

### ğŸ‰ ç³»ç»Ÿä¼˜åŠ¿
1. **å®Œæ•´çš„æ¶æ„è®¾è®¡**: æ¸…æ™°çš„åˆ†å±‚æ¶æ„ï¼ŒèŒè´£åˆ†ç¦»æ˜ç¡®
2. **é«˜è´¨é‡ä»£ç å®ç°**: è§„èŒƒçš„ä»£ç ç»“æ„å’Œè‰¯å¥½çš„æµ‹è¯•è¦†ç›–
3. **å…¨é¢çš„ä¸šåŠ¡åŠŸèƒ½**: å¤šAgentåä½œçš„å®Œæ•´äº¤æ˜“ç³»ç»Ÿ
4. **ç°ä»£æŠ€æœ¯æ ˆ**: FastAPI + SQLAlchemy + Redis + Celery

### âš ï¸ æ”¹è¿›å»ºè®®
1. **æ€§èƒ½ä¼˜åŒ–**: åŠ å¼ºå¼‚æ­¥ç¼–ç¨‹å’Œç¼“å­˜ç­–ç•¥
2. **ç›‘æ§ä½“ç³»**: å»ºç«‹å®Œå–„çš„æ€§èƒ½ç›‘æ§æœºåˆ¶
3. **æ¨¡å—åŒ–**: è¿›ä¸€æ­¥ç»†åŒ–å¤§å‹æ¨¡å—
4. **æ•°æ®åº“ä¼˜åŒ–**: æ·»åŠ æŸ¥è¯¢ä¼˜åŒ–å’Œç´¢å¼•ç­–ç•¥

### ğŸš€ éƒ¨ç½²å»ºè®®
1. **å®¹å™¨åŒ–éƒ¨ç½²**: ä½¿ç”¨Dockerè¿›è¡Œç¯å¢ƒéš”ç¦»
2. **è´Ÿè½½å‡è¡¡**: é…ç½®Nginxè¿›è¡Œè´Ÿè½½åˆ†å‘
3. **æ•°æ®åº“ä¼˜åŒ–**: é…ç½®è¿æ¥æ± å’Œè¯»å†™åˆ†ç¦»
4. **ç¼“å­˜ç­–ç•¥**: å®æ–½å¤šçº§ç¼“å­˜æœºåˆ¶

---

**ğŸ¯ ç»¼åˆè¯„åˆ†: {score.get("total_score", "N/A")}/100 ({score.get("grade", "N/A")})**

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {report["timestamp"]}*
"""

        return md

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="è¿è¡Œç®€åŒ–æ€§èƒ½åˆ†æ")
    parser.add_argument("--project-root", default=".", help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„")

    args = parser.parse_args()

    print("ğŸš€ å¤šAgentåŠ å¯†è´§å¸é‡åŒ–äº¤æ˜“ç³»ç»Ÿ - ç®€åŒ–æ€§èƒ½åˆ†æå™¨")
    print("=" * 60)

    analyzer = SimplePerformanceAnalyzer(args.project_root)

    try:
        # è¿è¡Œåˆ†æ
        analyzer.analyze_system()

        # ç”ŸæˆæŠ¥å‘Š
        report_path = analyzer.generate_report()

        # æ˜¾ç¤ºç»“æœ
        score = analyzer.report.get("performance_score", {}).get("total_score", "N/A")
        grade = analyzer.report.get("performance_score", {}).get("grade", "N/A")

        print(f"\nğŸ“Š æ€§èƒ½åˆ†æå®Œæˆï¼")
        print(f"ğŸ“ˆ æ€§èƒ½è¯„åˆ†: {score}/100 ({grade})")
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°:")
        print(f"   JSON: {report_path}")
        print(f"   Markdown: {report_path.replace('.json', '.md')}")

        # æ˜¾ç¤ºå…³é”®ç»Ÿè®¡
        code_stats = analyzer.report["analysis"].get("code_structure", {})
        arch_stats = analyzer.report["analysis"].get("architecture", {})

        print(f"\nğŸ“Š å…³é”®ç»Ÿè®¡:")
        print(f"   æ€»ä»£ç è¡Œæ•°: {code_stats.get('total_lines', 'N/A'):,}")
        print(f"   æ€»æ–‡ä»¶æ•°: {code_stats.get('total_files', 'N/A')}")
        print(f"   æµ‹è¯•æ–‡ä»¶: {code_stats.get('test_coverage', {}).get('test_files', 'N/A')}")
        print(f"   å¼‚æ­¥å‡½æ•°: {arch_stats.get('async_functions', 'N/A')}")
        print(f"   APIç«¯ç‚¹: {arch_stats.get('api_endpoints', 'N/A')}")

        print("=" * 60)

    except KeyboardInterrupt:
        print("\nâš ï¸ åˆ†æè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()